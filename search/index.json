[{"content":"A Simple Vulkan Compute Example in C++ Vulkan is great. It provides a cross-platform API to write applications that use the GPU to do graphics and general purpose compute. Designed from the ground-up to be a modern API, using Vulkan can be quite difficult so you better know what you\u0026rsquo;re doing if you plan to use Vulkan for your application.\nVulkan provides both a graphics and compute APIs and in this post I will focus on the compute part of it as I\u0026rsquo;m still not very familiar with the graphics side of it.\nI had a difficult time searching for simple Vulkan compute samples as the official Khronos Vulkan-Samples only include more elaborate examples. My goal was to write the minimal amount of code to get a compute shader running using Vulkan.\nI found two very useful resources that do more or less what I wanted:\n A Simple Vulkan Compute Example by Neil Henning Vulkan Compute Example by Slava Savenko  Neil\u0026rsquo;s post is great as it goes straight into the code but it uses the C API from Vulkan, so very verbose. I wanted to use vulkan.hpp as it provides a nice C++ interface to use Vulkan. The Vulkan C++ bindings are almost a one-to-one match with the C API, so theoretically I could just port Neil\u0026rsquo;s code to use the Vulkan C++ header but I found this task was not that simple. Slava\u0026rsquo;s sample did just that, however, as with most Vulkan samples out there, there is an infrastructure around the code to make it easier to write, namely classes with a lot of methods to abstract some of the resource management required to use Vulkan.\nDespite that, both links proved to be really useful when writing my own sample.\nThe goal is simple: Run a compute shader that squares the numbers from an input buffer and stores the results in an output buffer, i.e., run the equivalent of the following code but in the GPU, using Vulkan:\nstd::vector\u0026lt;int\u0026gt; Input, Output; for (int I = 0; I \u0026lt; Input.size(); ++I) { Output[I] = Input[I] * Input[I]; } So let\u0026rsquo;s start writing this program.\nInfrastructure I\u0026rsquo;m assuming you have the Vulkan SDK installed on your machine. For this program I\u0026rsquo;m going to use CMake and HLSL for the shader part.\nThe following CMake file can be used to build the program. I chose to compile the shader to SPIR-V ahead of time to make things simple in the C++ side. Using add_custom_target you can create a CMake target that will compile the Square.hlsl shader when building the project.\ncmake_minimum_required(VERSION 3.16)project(VulkanCompute)find_package(Vulkan REQUIRED)add_custom_command( OUTPUT \u0026#34;${CMAKE_BINARY_DIR}/Square.spv\u0026#34; COMMAND $ENV{VK_SDK_PATH}/Bin/dxc -T cs_6_0 -E \u0026#34;Main\u0026#34; -spirv -fvk-use-dx-layout -fspv-target-env=vulkan1.1 -Fo \u0026#34;${CMAKE_BINARY_DIR}/Square.spv\u0026#34; \u0026#34;Square.hlsl\u0026#34; DEPENDS \u0026#34;Square.hlsl\u0026#34; WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR} COMMENT \u0026#34;Buiding Shaders\u0026#34; )add_custom_target(ComputeShader DEPENDS \u0026#34;${CMAKE_BINARY_DIR}/Square.spv\u0026#34;)add_executable(VulkanCompute \u0026#34;main.cpp\u0026#34;)target_link_libraries(VulkanCompute PRIVATE Vulkan::Vulkan)add_dependencies(VulkanCompute ComputeShader)Preamble To use the Vulkan C++ header one just need to\n#include \u0026lt;vulkan/vulkan.hpp\u0026gt;Vulkan Instance - vk::Instance A Vulkan application starts with a vk::Instance, so lets create one:\nvk::ApplicationInfo AppInfo{ \u0026#34;VulkanCompute\u0026#34;, // Application Name  1, // Application Version  nullptr, // Engine Name or nullptr  0, // Engine Version  VK_API_VERSION_1_1 // Vulkan API version }; const std::vector\u0026lt;const char*\u0026gt; Layers = { \u0026#34;VK_LAYER_KHRONOS_validation\u0026#34; }; vk::InstanceCreateInfo InstanceCreateInfo(vk::InstanceCreateFlags(), // Flags  \u0026amp;AppInfo, // Application Info  Layers.size(), // Layers count  Layers.data()); // Layers vk::Instance Instance = vk::createInstance(InstanceCreateInfo); Here I\u0026rsquo;m enabling the VK_LAYER_KHRONOS_validation layer so we can have some help from Vulkan in case something goes wrong.\nEnumerating the Physical Devices - vk::PhysicalDevice A vk::PhysicalDevice represents, as the name suggests, the physical piece of hardware that we can use to run our application. We need to select a physical device from which we can create a logical device, vk::Device that we use to interact with it:\nvk::PhysicalDevice PhysicalDevice = Instance.enumeratePhysicalDevices().front(); vk::PhysicalDeviceProperties DeviceProps = PhysicalDevice.getProperties(); std::cout \u0026lt;\u0026lt; \u0026#34;Device Name : \u0026#34; \u0026lt;\u0026lt; DeviceProps.deviceName \u0026lt;\u0026lt; std::endl; const uint32_t ApiVersion = DeviceProps.apiVersion; std::cout \u0026lt;\u0026lt; \u0026#34;Vulkan Version : \u0026#34; \u0026lt;\u0026lt; VK_VERSION_MAJOR(ApiVersion) \u0026lt;\u0026lt; \u0026#34;.\u0026#34; \u0026lt;\u0026lt; VK_VERSION_MINOR(ApiVersion) \u0026lt;\u0026lt; \u0026#34;.\u0026#34; \u0026lt;\u0026lt; VK_VERSION_PATCH(ApiVersion); vk::PhysicalDeviceLimits DeviceLimits = DeviceProps.limits; std::cout \u0026lt;\u0026lt; \u0026#34;Max Compute Shared Memory Size: \u0026#34; \u0026lt;\u0026lt; DeviceLimits.maxComputeSharedMemorySize / 1024 \u0026lt;\u0026lt; \u0026#34; KB\u0026#34; \u0026lt;\u0026lt; std::endl; Here I\u0026rsquo;m just printing some information from the first physical device available in the machine.\nQueue Family Index - vk::QueueFamilyProperties We need a vk::Queue where we submit work to be done by the device, hopefully a GPU in this case. Note that extra code is required to make sure the selected device is the one you want, in case there are more than one available.\nVulkan supports different types of queues, so we need to query which queue family we need to create a queue suitable for compute work:\nstd::vector\u0026lt;vk::QueueFamilyProperties\u0026gt; QueueFamilyProps = PhysicalDevice.getQueueFamilyProperties(); auto PropIt = std::find_if(QueueFamilyProps.begin(), QueueFamilyProps.end(), [](const vk::QueueFamilyProperties\u0026amp; Prop) { return Prop.queueFlags \u0026amp; vk::QueueFlagBits::eCompute; }); const uint32_t ComputeQueueFamilyIndex = std::distance(QueueFamilyProps.begin(), PropIt); std::cout \u0026lt;\u0026lt; \u0026#34;Compute Queue Family Index: \u0026#34; \u0026lt;\u0026lt; ComputeQueueFamilyIndex \u0026lt;\u0026lt; std::endl; This will select a queue that has compute capabilities. This is equivalent to searching for a queue with the VK_QUEUE_COMPUTE_BIT flag using the C API.\nVulkan Device - vk::Device Creating a device requires a vk::DeviceQueueCreateInfo and a vk::DeviceCreateInfo:\nvk::DeviceQueueCreateInfo DeviceQueueCreateInfo(vk::DeviceQueueCreateFlags(), // Flags  ComputeQueueFamilyIndex, // Queue Family Index  1); // Number of Queues vk::DeviceCreateInfo DeviceCreateInfo(vk::DeviceCreateFlags(), // Flags  DeviceQueueCreateInfo); // Device Queue Create Info struct vk::Device Device = PhysicalDevice.createDevice(DeviceCreateInfo); Allocating Memory Allocating memory in Vulkan is a pain. There libraries that facilitate this task like AMD\u0026rsquo;s Vulkan Memory Allocator, but using this libraries is out of the scope for this post, also I wanted to see how to do it manually first.\nVulkan separates buffers memory. Buffers in Vulkan are just a view into a piece of memory that you also need to manually configure. Allocating memory then is split into three parts:\n Create the required buffers for the application Allocate the memory to back the buffers Bind the buffers to the memory  This separation allows programmers to fine tune memory usage by allocating a large chunk of memory for several buffers for example. For the sake of simplicity, each vk::Buffer will have its corresponding vk::Memory associated with it:\nCreating the buffers - vk::Buffer I\u0026rsquo;m going to create two buffers with 10 elements each:\nconst uint32_t NumElements = 10; const uint32_t BufferSize = NumElements * sizeof(int32_t); vk::BufferCreateInfo BufferCreateInfo{ vk::BufferCreateFlags(), // Flags  BufferSize, // Size  vk::BufferUsageFlagBits::eStorageBuffer, // Usage  vk::SharingMode::eExclusive, // Sharing mode  1, // Number of queue family indices  \u0026amp;ComputeQueueFamilyIndex // List of queue family indices }; vk::Buffer InBuffer = Device.createBuffer(BufferCreateInfo); vk::Buffer OutBuffer = Device.createBuffer(BufferCreateInfo); Allocating memory To allocate memory in Vulkan we first need to find the type of memory we actually require to back the buffers we have. The vk::Device provides a member function called vk::Device::getBufferMemoryRequirements that returns a vk::MemoryRequirements object with information so we can ask Vulkan how much memory to allocate for each buffer:\nvk::MemoryRequirements InBufferMemoryRequirements = Device.getBufferMemoryRequirements(InBuffer); vk::MemoryRequirements OutBufferMemoryRequirements = Device.getBufferMemoryRequirements(OutBuffer); With this information on hand we can query Vulkan for the memory type required to allocate memory that is visible from the host, i.e., memory that can be mapped on the host side:\nvk::PhysicalDeviceMemoryProperties MemoryProperties = PhysicalDevice.getMemoryProperties(); uint32_t MemoryTypeIndex = uint32_t(~0); vk::DeviceSize MemoryHeapSize = uint32_t(~0); for (uint32_t CurrentMemoryTypeIndex = 0; CurrentMemoryTypeIndex \u0026lt; MemoryProperties.memoryTypeCount; ++CurrentMemoryTypeIndex) { vk::MemoryType MemoryType = MemoryProperties.memoryTypes[CurrentMemoryTypeIndex]; if ((vk::MemoryPropertyFlagBits::eHostVisible \u0026amp; MemoryType.propertyFlags) \u0026amp;\u0026amp; (vk::MemoryPropertyFlagBits::eHostCoherent \u0026amp; MemoryType.propertyFlags)) { MemoryHeapSize = MemoryProperties.memoryHeaps[MemoryType.heapIndex].size; MemoryTypeIndex = CurrentMemoryTypeIndex; break; } } std::cout \u0026lt;\u0026lt; \u0026#34;Memory Type Index: \u0026#34; \u0026lt;\u0026lt; MemoryTypeIndex \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Memory Heap Size : \u0026#34; \u0026lt;\u0026lt; MemoryHeapSize / 1024 / 1024 / 1024 \u0026lt;\u0026lt; \u0026#34; GB\u0026#34; \u0026lt;\u0026lt; std::endl; And finally we can ask the device to allocate the required memory for our buffers:\nvk::MemoryAllocateInfo InBufferMemoryAllocateInfo(InBufferMemoryRequirements.size, MemoryTypeIndex); vk::MemoryAllocateInfo OutBufferMemoryAllocateInfo(OutBufferMemoryRequirements.size, MemoryTypeIndex); vk::DeviceMemory InBufferMemory = Device.allocateMemory(InBufferMemoryAllocateInfo); vk::DeviceMemory OutBufferMemory = Device.allocateMemory(InBufferMemoryAllocateInfo); The last step of the memory allocation part is to get a mapped pointer to this memory that can be used to copy data from the host to the device. For this simple example I\u0026rsquo;m just setting the value of each element as its index:\nint32_t* InBufferPtr = static_cast\u0026lt;int32_t*\u0026gt;(Device.mapMemory(InBufferMemory, 0, BufferSize)); for (int32_t I = 0; I \u0026lt; NumElements; ++I) { InBufferPtr[I] = I; } Device.unmapMemory(InBufferMemory); Binding Buffers to Memory Finally we can bind the buffers to the allocated memory:\nDevice.bindBufferMemory(InBuffer, InBufferMemory, 0); Device.bindBufferMemory(OutBuffer, OutBufferMemory, 0); And that concludes the memory allocation part of the program.\nCreating the Compute Pipeline - vk::Pipeline The next part of the process is to create the compute pipeline that will be used to run the compute shader on the GPU. Lets start with the HLSL shader we are going to run:\n[[vk::binding(0, 0)]] RWStructuredBuffer\u0026lt;int\u0026gt; InBuffer;\r[[vk::binding(1, 0)]] RWStructuredBuffer\u0026lt;int\u0026gt; OutBuffer;\r[numthreads(1, 1, 1)]\rvoid Main(uint3 DTid : SV_DispatchThreadID)\r{\rOutBuffer[DTid.x] = InBuffer[DTid.x] * InBuffer[DTid.x];\r}\rThe only difference from a regular HLSL shader are the annotations for each buffer. [[vk::binding(1, 0)]] means that a buffer will use binding 1 from descriptor set 0. Descriptor sets can be thought of a way to tell Vulkan how to the buffers we defined in the previous section are going to be passed to the pipeline. If you have an existing HLSL shader that you want to use but you can\u0026rsquo;t change the its source code to have the bindings, you can still set the bindings in the command line using dxc using the -fvk-bind-globals argument.\nWith the CMake setup defined in the beginning of the post, there will be a file called Square.spv in the build folder for the project. This file contains the SPIR-V bytecode representing this shader. The goal here is to load this shader as the compute stage of our pipeline.\nShader Module - vk::ShaderModule We start by reading the contents of the SPIR-V file and creating a vk::ShaderModule:\nstd::vector\u0026lt;char\u0026gt; ShaderContents; if (std::ifstream ShaderFile{ \u0026#34;Square.spv\u0026#34;, std::ios::binary | std::ios::ate }) { const size_t FileSize = ShaderFile.tellg(); ShaderFile.seekg(0); ShaderContents.resize(FileSize, \u0026#39;\\0\u0026#39;); ShaderFile.read(ShaderContents.data(), FileSize); } vk::ShaderModuleCreateInfo ShaderModuleCreateInfo( vk::ShaderModuleCreateFlags(), // Flags  ShaderContents.size(), // Code size  reinterpret_cast\u0026lt;const uint32_t*\u0026gt;(ShaderContents.data())); // Code vk::ShaderModule ShaderModule = Device.createShaderModule(ShaderModuleCreateInfo); Descriptor Set Layout - vk::DescriptorSetLayout Next we define the vk::DescriptorSetLayout. This object will tell Vulkan the layout of data to be passed into to the pipeline. Note that this is not the actual descriptor set, it is just the layout of the thing. This got me confused when I first saw it. The actual descriptor set is represented by a vk::DescriptorSet and it needs to be allocated using a descriptor pool. Vulkan is complicated, but you have control!\nLet\u0026rsquo;s define the vk::DescriptorSetLayout:\nconst std::vector\u0026lt;vk::DescriptorSetLayoutBinding\u0026gt; DescriptorSetLayoutBinding = { {0, vk::DescriptorType::eStorageBuffer, 1, vk::ShaderStageFlagBits::eCompute}, {1, vk::DescriptorType::eStorageBuffer, 1, vk::ShaderStageFlagBits::eCompute} }; vk::DescriptorSetLayoutCreateInfo DescriptorSetLayoutCreateInfo( vk::DescriptorSetLayoutCreateFlags(), DescriptorSetLayoutBinding); vk::DescriptorSetLayout DescriptorSetLayout = Device.createDescriptorSetLayout(DescriptorSetLayoutCreateInfo); The vk::DescriptorSetLayout is specified using a series of vk::DescriptorSetLayoutBinding objects. Each binding will assign an index to a buffer in the pipeline. With the vk::DescriptorSetLayout created we can move to create the layout of our compute pipeline. Yes, another layout, not the actual thing!\nPipeline Layout - vk::PipelineLayout vk::PipelineLayoutCreateInfo PipelineLayoutCreateInfo(vk::PipelineLayoutCreateFlags(), DescriptorSetLayout); vk::PipelineLayout PipelineLayout = Device.createPipelineLayout(PipelineLayoutCreateInfo); vk::PipelineCache PipelineCache = Device.createPipelineCache(vk::PipelineCacheCreateInfo()); Pipeline - vk::Pipeline Now we can finally create the compute pipeline:\nvk::PipelineShaderStageCreateInfo PipelineShaderCreateInfo( vk::PipelineShaderStageCreateFlags(), // Flags  vk::ShaderStageFlagBits::eCompute, // Stage  ShaderModule, // Shader Module  \u0026#34;Main\u0026#34;); // Shader Entry Point vk::ComputePipelineCreateInfo ComputePipelineCreateInfo( vk::PipelineCreateFlags(), // Flags  PipelineShaderCreateInfo, // Shader Create Info struct  PipelineLayout); // Pipeline Layout vk::Pipeline ComputePipeline = Device.createComputePipeline(PipelineCache, ComputePipelineCreateInfo); Creating the vk::DescriptorSet Descriptor sets must be allocated in a vk::DescriptorPool, so we need to create one first:\nvk::DescriptorPoolSize DescriptorPoolSize(vk::DescriptorType::eStorageBuffer, 2); vk::DescriptorPoolCreateInfo DescriptorPoolCreateInfo(vk::DescriptorPoolCreateFlags(), 1, DescriptorPoolSize); vk::DescriptorPool DescriptorPool = Device.createDescriptorPool(DescriptorPoolCreateInfo); Now we can finally allocate the descriptor set and update them to use our buffers:\nvk::DescriptorSetAllocateInfo DescriptorSetAllocInfo(DescriptorPool, 1, \u0026amp;DescriptorSetLayout); const std::vector\u0026lt;vk::DescriptorSet\u0026gt; DescriptorSets = Device.allocateDescriptorSets(DescriptorSetAllocInfo); vk::DescriptorSet DescriptorSet = DescriptorSets.front(); vk::DescriptorBufferInfo InBufferInfo(InBuffer, 0, NumElements * sizeof(int32_t)); vk::DescriptorBufferInfo OutBufferInfo(OutBuffer, 0, NumElements * sizeof(int32_t)); const std::vector\u0026lt;vk::WriteDescriptorSet\u0026gt; WriteDescriptorSets = { {DescriptorSet, 0, 0, 1, vk::DescriptorType::eStorageBuffer, nullptr, \u0026amp;InBufferInfo}, {DescriptorSet, 1, 0, 1, vk::DescriptorType::eStorageBuffer, nullptr, \u0026amp;OutBufferInfo}, }; Device.updateDescriptorSets(WriteDescriptorSets, {}); Submitting the work to the GPU Command Pool - vk::CommandPool To actually run this shader on the GPU we need to submit the work on a vk::Queue. We tell the queue to commands stored in a one or more vk::CommandBuffers. Commands must be allocated in a vk::CommandPool, so we need to create one first:\nvk::CommandPoolCreateInfo CommandPoolCreateInfo(vk::CommandPoolCreateFlags(), ComputeQueueFamilyIndex); vk::CommandPool CommandPool = Device.createCommandPool(CommandPoolCreateInfo); Command Buffers - vk::CommandBuffer Now we can use the command pool to allocate one or more command buffers:\nvk::CommandBufferAllocateInfo CommandBufferAllocInfo( CommandPool, // Command Pool  vk::CommandBufferLevel::ePrimary, // Level  1); // Num Command Buffers const std::vector\u0026lt;vk::CommandBuffer\u0026gt; CmdBuffers = Device.allocateCommandBuffers(CommandBufferAllocInfo); vk::CommandBuffer CmdBuffer = CmdBuffers.front(); Recording Commands We can now record commands in the vk::CommandBuffer object. To run the compute shader we need to bind the pipeline, descriptor sets and record a vk::CommandBuffer::dispatch call:\nvk::CommandBufferBeginInfo CmdBufferBeginInfo(vk::CommandBufferUsageFlagBits::eOneTimeSubmit); CmdBuffer.begin(CmdBufferBeginInfo); CmdBuffer.bindPipeline(vk::PipelineBindPoint::eCompute, ComputePipeline); CmdBuffer.bindDescriptorSets(vk::PipelineBindPoint::eCompute, // Bind point  PipelineLayout, // Pipeline Layout  0, // First descriptor set  { DescriptorSet }, // List of descriptor sets  {}); // Dynamic offsets CmdBuffer.dispatch(NumElements, 1, 1); CmdBuffer.end(); The vk::CommandBuffer::dispatch function takes the number of threads to launch in the device. In this example we are launching one thread for element.\nWith the vk::CommmandBuffer recorded we can finaly submit the work the GPU. We first get the vk::Queue from the vk::Device using the queue family index retrieved earlier and we create a vk::Fence. The fence is a mechanism we can use to wait for the compute shader to complete. After waiting we can read the results of our computation:\nvk::Queue Queue = Device.getQueue(ComputeQueueFamilyIndex, 0); vk::Fence Fence = Device.createFence(vk::FenceCreateInfo()); vk::SubmitInfo SubmitInfo(0, // Num Wait Semaphores  nullptr, // Wait Semaphores  nullptr, // Pipeline Stage Flags  1, // Num Command Buffers  \u0026amp;CmdBuffer); // List of command buffers Queue.submit({ SubmitInfo }, Fence); Device.waitForFences({ Fence }, // List of fences  true, // Wait All  uint64_t(-1)); // Timeout The final step is to map the output buffer and read the results. For this example we are just going to print the values in the terminal:\nInBufferPtr = static_cast\u0026lt;int32_t*\u0026gt;(Device.mapMemory(InBufferMemory, 0, BufferSize)); for (uint32_t I = 0; I \u0026lt; NumElements; ++I) { std::cout \u0026lt;\u0026lt; InBufferPtr[I] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } std::cout \u0026lt;\u0026lt; std::endl; Device.unmapMemory(InBufferMemory); int32_t* OutBufferPtr = static_cast\u0026lt;int32_t*\u0026gt;(Device.mapMemory(OutBufferMemory, 0, BufferSize)); for (uint32_t I = 0; I \u0026lt; NumElements; ++I) { std::cout \u0026lt;\u0026lt; OutBufferPtr[I] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } std::cout \u0026lt;\u0026lt; std::endl; Device.unmapMemory(OutBufferMemory); Cleaning We need to manually delete the resources used by our program or the validation layer will shout at you:\nDevice.resetCommandPool(CommandPool, vk::CommandPoolResetFlags()); Device.destroyFence(Fence); Device.destroyDescriptorSetLayout(DescriptorSetLayout); Device.destroyPipelineLayout(PipelineLayout); Device.destroyPipelineCache(PipelineCache); Device.destroyShaderModule(ShaderModule); Device.destroyPipeline(ComputePipeline); Device.destroyDescriptorPool(DescriptorPool); Device.destroyCommandPool(CommandPool); Device.freeMemory(InBufferMemory); Device.freeMemory(OutBufferMemory); Device.destroyBuffer(InBuffer); Device.destroyBuffer(OutBuffer); Device.destroy(); Instance.destroy(); The Vulkan C++ Header also has a raii set of objects that can be used to avoid manually cleaning resources, for example:\nvk::raii::Context context; vk::raii::Instance instance = vk::raii::su::makeInstance( context, AppName, EngineName ); // enumerate the physicalDevices vk::raii::PhysicalDevices physicalDevices( instance ); So this objects will clean their resources upon destruction.\nConclusion If you are here, well done, you can now use Vulkan to square a few numbers on the GPU =). Hopefully this will be useful to you in staring with Vulkan to run compute workloads on your GPU.\nThis code is pretty much in the order required to build your application so you should be able to copy-and-paste this code into your main function and have some numbers printed in the terminal. You can also find this code in this Github Repo ready to be built and executed.\nSee you next time!\n","date":"2021-07-07","permalink":"https://mcleary.github.io/posts/vulkan-compute-example/","tags":["vulkan","vulkan-compute","GPGPU"],"title":"Vulkan Compute Example"}]